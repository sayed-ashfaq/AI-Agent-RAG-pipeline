# Multi-Agent RAG Pipeline

---
## Overview
AI-Agent-RAG-Pipeline is an intelligent assistant designed for developers and AI enthusiasts to explore 
how agentic systems make autonomous **decisions**. It combines **real-time weather insights** and 
**document-based question** answering using **LangGraph**, **LangChain**, and **Qdrant**, showcasing how 
AI agents can dynamically choose and execute tools to deliver accurate, context-aware responses.
---
## How it works

### LangGraph Node Workflow

<div align="center">
  <img src="resources/workflow.png" alt="LangGraph Node Workflow" width="250"/>
</div>)

- AI-Agent-RAG-Pipeline is an intelligent agentic application built using LangGraph and LangChain 
- it dynamically decides when to fetch real-time weather data or perform document-based question answering using Retrieval-Augmented 
Generation (RAG). 
- It leverages a Qdrant vector store for context retrieval, 
- Integrates custom logging, exception handling
- Evaluation via LangSmith, and includes pytest-based testing for reliability.  
- A Streamlit interface for user interaction and visual assets 
- Illustrated test cases, evaluations, and workflow graphs.
This approach ensures that responses are grounded in the actual content of your resume rather than generic advice.
---

## Features
- Agentic workflow using LangGraph  
- Real-time weather data via OpenWeatherMap API  
- Document-based Q&A using Retrieval-Augmented Generation (RAG)  
- Qdrant vector database for storing and retrieving embeddings  
- Custom logger and exception handling  
- Evaluation with LangSmith  
- Unit tests with Pytest  
- Streamlit interface for user interaction
---

## ğŸ“¦ Setup Instructions

1. **Clone the Repository**
   ```bash
   git clone https://github.com/sayed-ashfaq/AI-Agent-RAG-Pipeline.git
   cd AI-Agent-RAG-Pipeline

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate     # On Windows: venv\Scripts\activate
   
3. **Add Environment Variables**
   ```bash
   Create a .env file in the project root:
   
   OPENWEATHER_API_KEY=your_api_key_here
   OPENAI_API_KEY=your_langchain_api_key
   LANGSMITH_VARIABLES(OPTIONAL) if you want to trace you agent
4. **Update Configuration (Optional)**<br>
Modify values in config.yaml for your own llm/embedding models and other hyperparameters.

5. **Run the Application**
   ```bash
   streamlit run Chat_Engine.py
---
ğŸ§© Implementation Details

The system follows a modular, agentic workflow built using LangGraph:

1. LLM Node â€“ Acts as the decision-maker, determining whether to use a tool or respond directly.
2. Tool Node â€“ Executes the chosen tool (Weather or RAG) and returns the result.
3. should continue Loop â€“ Passes control back to the LLM node to decide whether to continue or end the conversation.
4. Qdrant Vector Store â€“ Manages embeddings and supports document retrieval for the RAG pipeline.
5. Custom Logger & Exception Handler â€“ Ensures consistent debugging and traceability.
6. LangSmith Evaluation â€“ Monitors LLM performance, correctness, and tool usage.
7. T Suite (Pytest) â€“ validated weather API, RAG flow, and decision graph consistency.
---
## ğŸ“¸ Screenshots & Visuals

### Streamlit Interface
![App UI](assets/ui/app_ui.png)

### LangSmith Evaluation Results
![LangSmith Eval](assets/evals/langsmith_eval.png)

### Workflow Graph
![Agent Workflow](assets/graphs/agent_graph.png)

### Logs & Test Results
![Logs and Tests](assets/logs/test_results.png)

## Project Structure
```bash
## Project Structure
AI-Agent-RAG-pipeline/
â”œâ”€â”€ data/
â”‚   # Sample documents & PDFs for RAG processing and evaluation
â”‚
â”œâ”€â”€ evaluations/
â”‚   # LangSmith evaluation notebooks
â”‚   â””â”€â”€ langsmitheval.ipynb
â”‚
â”œâ”€â”€ notebooks/
â”‚   # Notebooks for prototyping, testing, and experiments
â”‚   â”œâ”€â”€ experiment.ipynb
â”‚   â”œâ”€â”€ prototype.ipynb
â”‚   â”œâ”€â”€ vector_service.ipynb
â”‚   â””â”€â”€ weather_tool.ipynb
â”‚
â”œâ”€â”€ pages/
â”‚   # Front-end/Streamlit pages (if any)
â”‚   â””â”€â”€ 1_About.py
â”‚
â”œâ”€â”€ resources/
â”‚   # Images/screenshots for README or evaluation documentation
â”‚   # (e.g., LangSmith visuals, pytest results)
â”‚
â”œâ”€â”€ logs/
â”‚   # Log files for debugging and workflow runs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.yaml               # App configuration (API keys, paths)
â”‚   â”‚
â”‚   â”œâ”€â”€ prompt_library/
â”‚   â”‚   â””â”€â”€ system_prompt.py          # System prompts for LLM agents
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ rag_agent/                # Core RAG agent logic
â”‚   â”‚   â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ wheather_agent/           # Weather tool logic (rename if needed)
â”‚   â”‚       â”œâ”€â”€ weather.py
â”‚   â”‚       â””â”€â”€ schemas.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config_loader.py          # Load configurations
â”‚   â”‚   â””â”€â”€ model_loader.py           # Load models
â”‚   â”‚
â”‚   â””â”€â”€ workflow/
â”‚       â””â”€â”€ agent_workflow.py         # LangGraph pipeline orchestration
â”‚   
â”œâ”€â”€ tests/
â”‚   # Unit tests for RAG, weather, and agents
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_agent_rag.py
â”‚   â””â”€â”€ test_weather_api.py
â”‚
â”œâ”€â”€ custom_logger/
â”‚   â””â”€â”€ logger.py                      # Centralized logging utility
â”‚
â”œâ”€â”€ exception_handler/
â”‚   â””â”€â”€ agent_exceptions.py            # Custom exceptions for agents
â”‚
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ meta.json
â”‚   â””â”€â”€ collection/
â”‚       # SQLite DBs for different vector collections
â”‚       â””â”€â”€ second-collection/
â”‚           â””â”€â”€ storage.sqlite
â”‚
â”œâ”€â”€ .env      # for storing environment vairables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”‚
â””â”€â”€ Chat_engine.py                 # Main chat engine orchestrating agents

```
### ğŸ› ï¸ Future Enhancements

- Multi-modal document support (images, tables)
- Advanced filtering and search options
- Integrate additional APIs (news, finance, knowledge)
- Deploy as a REST or FastAPI microservice


